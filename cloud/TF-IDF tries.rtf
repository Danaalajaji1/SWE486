{\rtf1\ansi\ansicpg1252\cocoartf2761
\cocoatextscaling0\cocoaplatform0{\fonttbl\f0\fswiss\fcharset0 Helvetica;\f1\froman\fcharset0 Times-Roman;}
{\colortbl;\red255\green255\blue255;\red0\green0\blue0;}
{\*\expandedcolortbl;;\cssrgb\c0\c0\c0;}
\paperw11900\paperh16840\margl1440\margr1440\vieww11520\viewh8400\viewkind0
\pard\tx566\tx1133\tx1700\tx2267\tx2834\tx3401\tx3968\tx4535\tx5102\tx5669\tx6236\tx6803\pardirnatural\partightenfactor0

\f0\fs24 \cf0 from pyspark.ml.feature import HashingTF, IDF, Tokenizer\
from pyspark.ml.classification import LogisticRegression\
from pyspark.ml.evaluation import MulticlassClassificationEvaluator\
from pyspark.sql.functions import col\
from pyspark.ml.feature import StringIndexer\
from pyspark.ml import Pipeline\
\
# Load your dataset\
df = spark.read.parquet("/Users/hoorrml/Desktop/dataset")\
\
# Filter and select necessary columns\
df_filtered = df.filter((col("language") == "ar") | (col("language") == "en"))\
df_selected = df_filtered.select("plain_text", "categories")\
\
# Sample smaller fraction\
df_sample = df_selected.sample(fraction=0.05, seed=42)\
\
# Tokenizer\
tokenizer = Tokenizer(inputCol="plain_text", outputCol="words")\
\
# TF-IDF\
hashing_tf = HashingTF(inputCol="words", outputCol="raw_features", numFeatures=1)\
idf = IDF(inputCol="raw_features", outputCol="features")\
\
# Indexing the 'categories' column to create labels\
indexer = StringIndexer(inputCol="categories", outputCol="label")\
\
# Logistic Regression Classifier\
classifier = LogisticRegression(featuresCol="features", labelCol="label", maxIter=1)\
\
# Create a pipeline\
pipeline = Pipeline(stages=[tokenizer, hashing_tf, idf, indexer, classifier])\
\
# Train-test split\
train_data, test_data = df_sample.randomSplit([0.8, 0.2], seed=123)\
\
# Train the model\
model = pipeline.fit(train_data)\
\
# Make predictions\
predictions = model.transform(test_data)\
\
# Evaluate accuracy\
evaluator = MulticlassClassificationEvaluator(labelCol="label", predictionCol="prediction", metricName="accuracy")\
accuracy = evaluator.evaluate(predictions)\
\
# Evaluate precision\
evaluator.setMetricName("weightedPrecision")\
precision = evaluator.evaluate(predictions)\
\
# Print accuracy and precision\
print(f"Accuracy: \{accuracy\}")\
print(f"Precision: \{precision\}")\
\
\pard\pardeftab720\partightenfactor0

\f1 \cf0 \expnd0\expndtw0\kerning0
\outl0\strokewidth0 \strokec2 using TF-IDF which also got to memory out of bound}